{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ZFNet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2V7dB_RKwYz"
      },
      "source": [
        "ZFNet implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y23i7y0KKWxy",
        "outputId": "ddb48cfb-1553-4d87-b45b-81ce629869da"
      },
      "source": [
        "import numpy\r\n",
        "\r\n",
        "print(tf.__version__)\r\n",
        "print(tf.keras.__version__)\r\n",
        "print(numpy.__version__)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.0\n",
            "2.4.0\n",
            "1.19.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSwcnTkv1Sr6"
      },
      "source": [
        "'''\r\n",
        "ZFNet uses deconvolutional networks known as deconvnet to visualize features.\r\n",
        "Deconvnet is the reverse of convolutional network that shows where the extracted feature comes from.\r\n",
        "'''\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "#import mnist data\r\n",
        "mnist = tf.keras.datasets.mnist\r\n",
        "\r\n",
        "#divide training and test data\r\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\r\n",
        "\r\n",
        "training_images = training_images[:1000]\r\n",
        "training_labels = training_labels[:1000]\r\n",
        "test_images = test_images[:100]\r\n",
        "test_labels = test_labels[:100]\r\n",
        "\r\n",
        "training_images = tf.map_fn(lambda i: tf.stack([i]*3, axis=-1), training_images).numpy()\r\n",
        "test_images = tf.map_fn(lambda i: tf.stack([i]*3, axis=-1), test_images).numpy()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmAYrl-31ZVU"
      },
      "source": [
        "#resize/reshape data \r\n",
        "training_images = tf.image.resize(training_images, [224, 224]).numpy()\r\n",
        "test_images = tf.image.resize(test_images, [224, 224]).numpy()\r\n",
        "\r\n",
        "training_images = training_images.reshape(1000, 224, 224, 3)\r\n",
        "training_images = training_images / 255.0 \r\n",
        "test_images = test_images.reshape(100, 224, 224, 3)\r\n",
        "test_images = test_images / 255.0\r\n",
        "\r\n",
        "#one-hot encoding\r\n",
        "training_labels = tf.keras.utils.to_categorical(training_labels, num_classes=10)\r\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=10)\r\n",
        "\r\n",
        "num_len_train = int(0.8 * len(training_images))\r\n",
        "\r\n",
        "ttraining_images = training_images[:num_len_train]\r\n",
        "ttraining_labels = training_labels[:num_len_train]\r\n",
        "\r\n",
        "valid_images = training_images[num_len_train:]\r\n",
        "valid_labels = training_labels[num_len_train:]\r\n",
        "\r\n",
        "training_images = ttraining_images\r\n",
        "training_labels = ttraining_labels"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4R7np2vNl4Qr",
        "outputId": "c716e378-2989-4c60-9a99-104cb2c63308"
      },
      "source": [
        "#model\r\n",
        "model = tf.keras.models.Sequential([\r\n",
        "    #96 convolutions with 7x7 with a stride of 2, relu activation\r\n",
        "    #3x3 max pooling with stride 2, and local contrast normalization                                \r\n",
        "\t\ttf.keras.layers.Conv2D(96, (7, 7), strides=(2, 2), activation='relu',\r\n",
        "\t\t\tinput_shape=(224, 224, 3)),\r\n",
        "\t\ttf.keras.layers.MaxPooling2D(3, strides=2),\r\n",
        "    tf.keras.layers.Lambda(lambda x: tf.image.per_image_standardization(x)),\r\n",
        "\r\n",
        "    #256 filters of 5x5, pooled, local contrast normalization\r\n",
        "\t\ttf.keras.layers.Conv2D(256, (5, 5), strides=(2, 2), activation='relu'),\r\n",
        "\t\ttf.keras.layers.MaxPooling2D(3, strides=2),\r\n",
        "    tf.keras.layers.Lambda(lambda x: tf.image.per_image_standardization(x)),\r\n",
        "\r\n",
        "    #384 filters of 3x3\r\n",
        "\t\ttf.keras.layers.Conv2D(384, (3, 3), activation='relu'),\r\n",
        "\r\n",
        "    #384 filters of 3x3\r\n",
        "\t\ttf.keras.layers.Conv2D(384, (3, 3), activation='relu'),\r\n",
        "\r\n",
        "    #256 filters of 3x3, maxpooling of 3x3 with stride 2\r\n",
        "\t\ttf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\r\n",
        "\t\ttf.keras.layers.MaxPooling2D(3, strides=2),\r\n",
        "\r\n",
        "    tf.keras.layers.Flatten(),\r\n",
        "    #4096 neurons\r\n",
        "\t\ttf.keras.layers.Dense(4096),\r\n",
        "    #4096 neurons\r\n",
        "\t\ttf.keras.layers.Dense(4096),\r\n",
        "    #1000 neurons(=number of classes in ImageNet)\r\n",
        "\t\ttf.keras.layers.Dense(10, activation='softmax')\r\n",
        "\t])\r\n",
        "\r\n",
        "'''\r\n",
        "Local Contrast Normalization is a type of normalization that performs local subtraction and division normalizations, \r\n",
        "enforcing a sort of local competition between adjacent features in a feature map, \r\n",
        "and between features at the same spatial location in different feature maps.\r\n",
        "'''\r\n",
        "\r\n",
        "#compile model\r\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.01, momentum=0.9), \r\n",
        "              loss='categorical_crossentropy', \r\n",
        "              metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(5)])\r\n",
        "\r\n",
        "'''\r\n",
        "TopK Categorical Accuracy calculates the percentage of records \r\n",
        "for which the targets are in the top K predictions.\r\n",
        "'''\r\n",
        "\r\n",
        "#callback\r\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \r\n",
        "                                            \t\tfactor=0.1, patience=1, \r\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tmin_lr=0.00001)\r\n",
        "\r\n",
        "#train model\r\n",
        "model.fit(training_images, training_labels, batch_size=128, \r\n",
        "          validation_data=(valid_images, valid_labels), \r\n",
        "\t\t\t\t\tepochs=50, callbacks=[reduce_lr])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "7/7 [==============================] - 91s 13s/step - loss: 2.6557 - accuracy: 0.1232 - top_k_categorical_accuracy: 0.5284 - val_loss: 2.6267 - val_accuracy: 0.2250 - val_top_k_categorical_accuracy: 0.5650\n",
            "Epoch 2/50\n",
            "7/7 [==============================] - 87s 12s/step - loss: 2.1445 - accuracy: 0.2890 - top_k_categorical_accuracy: 0.7308 - val_loss: 1.5845 - val_accuracy: 0.4700 - val_top_k_categorical_accuracy: 0.8600\n",
            "Epoch 3/50\n",
            "7/7 [==============================] - 87s 12s/step - loss: 1.8709 - accuracy: 0.4746 - top_k_categorical_accuracy: 0.8248 - val_loss: 1.7319 - val_accuracy: 0.4850 - val_top_k_categorical_accuracy: 0.8400\n",
            "Epoch 4/50\n",
            "7/7 [==============================] - 87s 12s/step - loss: 1.7710 - accuracy: 0.5717 - top_k_categorical_accuracy: 0.8787 - val_loss: 1.6732 - val_accuracy: 0.5750 - val_top_k_categorical_accuracy: 0.9200\n",
            "Epoch 5/50\n",
            "7/7 [==============================] - 87s 12s/step - loss: 1.8393 - accuracy: 0.5353 - top_k_categorical_accuracy: 0.9325 - val_loss: 2.1411 - val_accuracy: 0.5350 - val_top_k_categorical_accuracy: 0.8650\n",
            "Epoch 6/50\n",
            "7/7 [==============================] - 87s 12s/step - loss: 1.5977 - accuracy: 0.5870 - top_k_categorical_accuracy: 0.9227 - val_loss: 1.5319 - val_accuracy: 0.6050 - val_top_k_categorical_accuracy: 0.9000\n",
            "Epoch 7/50\n",
            "7/7 [==============================] - 87s 12s/step - loss: 1.1101 - accuracy: 0.6928 - top_k_categorical_accuracy: 0.9636 - val_loss: 1.4495 - val_accuracy: 0.6100 - val_top_k_categorical_accuracy: 0.9250\n",
            "Epoch 8/50\n",
            "7/7 [==============================] - 90s 13s/step - loss: 1.0569 - accuracy: 0.7115 - top_k_categorical_accuracy: 0.9712 - val_loss: 1.3945 - val_accuracy: 0.6250 - val_top_k_categorical_accuracy: 0.9300\n",
            "Epoch 9/50\n",
            "7/7 [==============================] - 87s 12s/step - loss: 0.9828 - accuracy: 0.7266 - top_k_categorical_accuracy: 0.9752 - val_loss: 1.3381 - val_accuracy: 0.6500 - val_top_k_categorical_accuracy: 0.9350\n",
            "Epoch 10/50\n",
            "7/7 [==============================] - 87s 12s/step - loss: 0.8871 - accuracy: 0.7439 - top_k_categorical_accuracy: 0.9806 - val_loss: 1.2893 - val_accuracy: 0.6600 - val_top_k_categorical_accuracy: 0.9450\n",
            "Epoch 11/50\n",
            "7/7 [==============================] - 87s 12s/step - loss: 0.8550 - accuracy: 0.7598 - top_k_categorical_accuracy: 0.9811 - val_loss: 1.2499 - val_accuracy: 0.6750 - val_top_k_categorical_accuracy: 0.9450\n",
            "Epoch 12/50\n",
            "7/7 [==============================] - 87s 12s/step - loss: 0.8555 - accuracy: 0.7690 - top_k_categorical_accuracy: 0.9753 - val_loss: 1.2182 - val_accuracy: 0.6800 - val_top_k_categorical_accuracy: 0.9500\n",
            "Epoch 13/50\n",
            "7/7 [==============================] - 87s 12s/step - loss: 0.8223 - accuracy: 0.7711 - top_k_categorical_accuracy: 0.9756 - val_loss: 1.1930 - val_accuracy: 0.6850 - val_top_k_categorical_accuracy: 0.9450\n",
            "Epoch 14/50\n",
            "7/7 [==============================] - 87s 12s/step - loss: 0.7885 - accuracy: 0.7768 - top_k_categorical_accuracy: 0.9840 - val_loss: 1.1729 - val_accuracy: 0.6850 - val_top_k_categorical_accuracy: 0.9500\n",
            "Epoch 15/50\n",
            "7/7 [==============================] - 91s 13s/step - loss: 0.7844 - accuracy: 0.7873 - top_k_categorical_accuracy: 0.9768 - val_loss: 1.1562 - val_accuracy: 0.6900 - val_top_k_categorical_accuracy: 0.9450\n",
            "Epoch 16/50\n",
            "7/7 [==============================] - 87s 12s/step - loss: 0.7072 - accuracy: 0.7964 - top_k_categorical_accuracy: 0.9759 - val_loss: 1.1416 - val_accuracy: 0.7000 - val_top_k_categorical_accuracy: 0.9450\n",
            "Epoch 17/50\n",
            "7/7 [==============================] - 87s 12s/step - loss: 0.7152 - accuracy: 0.8248 - top_k_categorical_accuracy: 0.9773 - val_loss: 1.1295 - val_accuracy: 0.7000 - val_top_k_categorical_accuracy: 0.9450\n",
            "Epoch 18/50\n",
            "7/7 [==============================] - 87s 12s/step - loss: 0.7585 - accuracy: 0.8004 - top_k_categorical_accuracy: 0.9788 - val_loss: 1.1183 - val_accuracy: 0.6950 - val_top_k_categorical_accuracy: 0.9450\n",
            "Epoch 19/50\n",
            "7/7 [==============================] - 87s 12s/step - loss: 0.6797 - accuracy: 0.8407 - top_k_categorical_accuracy: 0.9820 - val_loss: 1.1087 - val_accuracy: 0.6950 - val_top_k_categorical_accuracy: 0.9450\n",
            "Epoch 20/50\n",
            "7/7 [==============================] - 87s 12s/step - loss: 0.7520 - accuracy: 0.8173 - top_k_categorical_accuracy: 0.9804 - val_loss: 1.0993 - val_accuracy: 0.7000 - val_top_k_categorical_accuracy: 0.9450\n",
            "Epoch 21/50\n",
            "7/7 [==============================] - 87s 12s/step - loss: 0.7340 - accuracy: 0.8268 - top_k_categorical_accuracy: 0.9774 - val_loss: 1.0899 - val_accuracy: 0.7050 - val_top_k_categorical_accuracy: 0.9450\n",
            "Epoch 22/50\n",
            "7/7 [==============================] - 90s 13s/step - loss: 0.7804 - accuracy: 0.8077 - top_k_categorical_accuracy: 0.9702 - val_loss: 1.0807 - val_accuracy: 0.7100 - val_top_k_categorical_accuracy: 0.9500\n",
            "Epoch 23/50\n",
            "7/7 [==============================] - 87s 12s/step - loss: 0.7432 - accuracy: 0.8311 - top_k_categorical_accuracy: 0.9778 - val_loss: 1.0733 - val_accuracy: 0.7150 - val_top_k_categorical_accuracy: 0.9500\n",
            "Epoch 24/50\n",
            "7/7 [==============================] - 87s 12s/step - loss: 0.6101 - accuracy: 0.8429 - top_k_categorical_accuracy: 0.9837 - val_loss: 1.0659 - val_accuracy: 0.7150 - val_top_k_categorical_accuracy: 0.9500\n",
            "Epoch 25/50\n",
            "7/7 [==============================] - 87s 12s/step - loss: 0.6784 - accuracy: 0.8299 - top_k_categorical_accuracy: 0.9814 - val_loss: 1.0591 - val_accuracy: 0.7150 - val_top_k_categorical_accuracy: 0.9500\n",
            "Epoch 26/50\n",
            "7/7 [==============================] - 87s 12s/step - loss: 0.7380 - accuracy: 0.8228 - top_k_categorical_accuracy: 0.9763 - val_loss: 1.0526 - val_accuracy: 0.7250 - val_top_k_categorical_accuracy: 0.9500\n",
            "Epoch 27/50\n",
            "7/7 [==============================] - 87s 12s/step - loss: 0.6537 - accuracy: 0.8345 - top_k_categorical_accuracy: 0.9791 - val_loss: 1.0472 - val_accuracy: 0.7350 - val_top_k_categorical_accuracy: 0.9500\n",
            "Epoch 28/50\n",
            "7/7 [==============================] - 87s 12s/step - loss: 0.6511 - accuracy: 0.8238 - top_k_categorical_accuracy: 0.9808 - val_loss: 1.0410 - val_accuracy: 0.7350 - val_top_k_categorical_accuracy: 0.9500\n",
            "Epoch 29/50\n",
            "7/7 [==============================] - 90s 13s/step - loss: 0.7019 - accuracy: 0.8293 - top_k_categorical_accuracy: 0.9789 - val_loss: 1.0351 - val_accuracy: 0.7350 - val_top_k_categorical_accuracy: 0.9500\n",
            "Epoch 30/50\n",
            "7/7 [==============================] - 87s 12s/step - loss: 0.6553 - accuracy: 0.8194 - top_k_categorical_accuracy: 0.9798 - val_loss: 1.0297 - val_accuracy: 0.7350 - val_top_k_categorical_accuracy: 0.9500\n",
            "Epoch 31/50\n",
            "7/7 [==============================] - 87s 12s/step - loss: 0.6692 - accuracy: 0.8161 - top_k_categorical_accuracy: 0.9792 - val_loss: 1.0244 - val_accuracy: 0.7500 - val_top_k_categorical_accuracy: 0.9500\n",
            "Epoch 32/50\n",
            "7/7 [==============================] - 87s 12s/step - loss: 0.5892 - accuracy: 0.8413 - top_k_categorical_accuracy: 0.9830 - val_loss: 1.0193 - val_accuracy: 0.7500 - val_top_k_categorical_accuracy: 0.9500\n",
            "Epoch 33/50\n",
            "7/7 [==============================] - 87s 12s/step - loss: 0.6052 - accuracy: 0.8303 - top_k_categorical_accuracy: 0.9868 - val_loss: 1.0147 - val_accuracy: 0.7500 - val_top_k_categorical_accuracy: 0.9500\n",
            "Epoch 34/50\n",
            "7/7 [==============================] - 87s 12s/step - loss: 0.5799 - accuracy: 0.8353 - top_k_categorical_accuracy: 0.9852 - val_loss: 1.0094 - val_accuracy: 0.7500 - val_top_k_categorical_accuracy: 0.9500\n",
            "Epoch 35/50\n",
            "7/7 [==============================] - 87s 12s/step - loss: 0.6242 - accuracy: 0.8230 - top_k_categorical_accuracy: 0.9805 - val_loss: 1.0056 - val_accuracy: 0.7550 - val_top_k_categorical_accuracy: 0.9500\n",
            "Epoch 36/50\n",
            "7/7 [==============================] - 90s 13s/step - loss: 0.6631 - accuracy: 0.8263 - top_k_categorical_accuracy: 0.9832 - val_loss: 1.0014 - val_accuracy: 0.7550 - val_top_k_categorical_accuracy: 0.9500\n",
            "Epoch 37/50\n",
            "7/7 [==============================] - 87s 12s/step - loss: 0.5431 - accuracy: 0.8544 - top_k_categorical_accuracy: 0.9862 - val_loss: 0.9977 - val_accuracy: 0.7550 - val_top_k_categorical_accuracy: 0.9500\n",
            "Epoch 38/50\n",
            "7/7 [==============================] - 87s 12s/step - loss: 0.6341 - accuracy: 0.8289 - top_k_categorical_accuracy: 0.9834 - val_loss: 0.9936 - val_accuracy: 0.7550 - val_top_k_categorical_accuracy: 0.9500\n",
            "Epoch 39/50\n",
            "7/7 [==============================] - 87s 12s/step - loss: 0.6311 - accuracy: 0.8322 - top_k_categorical_accuracy: 0.9837 - val_loss: 0.9894 - val_accuracy: 0.7550 - val_top_k_categorical_accuracy: 0.9500\n",
            "Epoch 40/50\n",
            "7/7 [==============================] - 87s 12s/step - loss: 0.6360 - accuracy: 0.8238 - top_k_categorical_accuracy: 0.9829 - val_loss: 0.9852 - val_accuracy: 0.7600 - val_top_k_categorical_accuracy: 0.9500\n",
            "Epoch 41/50\n",
            "7/7 [==============================] - 87s 12s/step - loss: 0.6195 - accuracy: 0.8408 - top_k_categorical_accuracy: 0.9806 - val_loss: 0.9814 - val_accuracy: 0.7600 - val_top_k_categorical_accuracy: 0.9500\n",
            "Epoch 42/50\n",
            "7/7 [==============================] - 87s 12s/step - loss: 0.5595 - accuracy: 0.8420 - top_k_categorical_accuracy: 0.9838 - val_loss: 0.9775 - val_accuracy: 0.7600 - val_top_k_categorical_accuracy: 0.9500\n",
            "Epoch 43/50\n",
            "7/7 [==============================] - 90s 13s/step - loss: 0.5685 - accuracy: 0.8463 - top_k_categorical_accuracy: 0.9841 - val_loss: 0.9734 - val_accuracy: 0.7600 - val_top_k_categorical_accuracy: 0.9500\n",
            "Epoch 44/50\n",
            "7/7 [==============================] - 87s 12s/step - loss: 0.5501 - accuracy: 0.8437 - top_k_categorical_accuracy: 0.9876 - val_loss: 0.9699 - val_accuracy: 0.7600 - val_top_k_categorical_accuracy: 0.9500\n",
            "Epoch 45/50\n",
            "7/7 [==============================] - 87s 12s/step - loss: 0.6045 - accuracy: 0.8497 - top_k_categorical_accuracy: 0.9803 - val_loss: 0.9668 - val_accuracy: 0.7600 - val_top_k_categorical_accuracy: 0.9550\n",
            "Epoch 46/50\n",
            "7/7 [==============================] - 87s 12s/step - loss: 0.5807 - accuracy: 0.8336 - top_k_categorical_accuracy: 0.9813 - val_loss: 0.9635 - val_accuracy: 0.7650 - val_top_k_categorical_accuracy: 0.9550\n",
            "Epoch 47/50\n",
            "7/7 [==============================] - 87s 12s/step - loss: 0.6064 - accuracy: 0.8345 - top_k_categorical_accuracy: 0.9817 - val_loss: 0.9600 - val_accuracy: 0.7650 - val_top_k_categorical_accuracy: 0.9550\n",
            "Epoch 48/50\n",
            "7/7 [==============================] - 87s 12s/step - loss: 0.5502 - accuracy: 0.8481 - top_k_categorical_accuracy: 0.9798 - val_loss: 0.9572 - val_accuracy: 0.7650 - val_top_k_categorical_accuracy: 0.9550\n",
            "Epoch 49/50\n",
            "7/7 [==============================] - 87s 12s/step - loss: 0.5742 - accuracy: 0.8428 - top_k_categorical_accuracy: 0.9799 - val_loss: 0.9540 - val_accuracy: 0.7650 - val_top_k_categorical_accuracy: 0.9550\n",
            "Epoch 50/50\n",
            "7/7 [==============================] - 90s 12s/step - loss: 0.5388 - accuracy: 0.8601 - top_k_categorical_accuracy: 0.9828 - val_loss: 0.9503 - val_accuracy: 0.7600 - val_top_k_categorical_accuracy: 0.9550\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb8e1656668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_eJuORV1RhY",
        "outputId": "457e3e30-f5c3-4bbd-c3e5-265775458d27"
      },
      "source": [
        "#Evaluate model\r\n",
        "print(\"\\n Accuracy: %.4f\" % (model.evaluate(test_images, test_labels)[1]))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 3s 643ms/step - loss: 0.6950 - accuracy: 0.8300 - top_k_categorical_accuracy: 0.9900\n",
            "\n",
            " Accuracy: 0.8300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMz6x2-WTaUo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}