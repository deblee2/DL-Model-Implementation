# -*- coding: utf-8 -*-
"""Alexnet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FD1yPrZFyR03IU5jvJrcvoUMH4lPHq6_

Alexnet implementation
"""

import numpy as np
import tensorflow as tf

from keras.utils import np_utils
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D

#seed value
seed = 0
np.random.seed(seed)
tf.random.set_seed(3)

#import data
mnist = tf.keras.datasets.mnist
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()
X_train = train_images
Y_train = train_labels
X_test = test_images
Y_test = test_labels

#reshape data
X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')/255
X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')/255

#one-hot encoding
Y_train = np_utils.to_categorical(Y_train, 10)
Y_test = np_utils.to_categorical(Y_test, 10)

#set model
model = Sequential()
model.add(Conv2D(28, kernel_size=(5, 5), input_shape=(28, 28, 1), activation='relu'))
model.add(MaxPooling2D(pool_size=2))
model.add(Conv2D(20, (5, 5), activation='relu'))
model.add(MaxPooling2D(pool_size=2))
model.add(Flatten())
model.add(Dense(127, activation='relu'))
model.add(Dense(10, activation='softmax'))

model.summary()

#optimize model
from tensorflow.keras.callbacks import EarlyStopping
early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)

#compile model
model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])

#train model
model.fit(X_train, Y_train, validation_data= (X_test, Y_test), epochs=20, callbacks=[early_stopping_callback])

#evaluate model
print("\n Accuracy: %.4f" % (model.evaluate(X_test, Y_test)[1]))

